{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f1da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook environment.\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "import botocore\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff069c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge xarray dask netCDF4 bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd03dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_bucket = 'era5-pds'\n",
    "\n",
    "# AWS access / secret keys required\n",
    "# s3 = boto3.resource('s3')\n",
    "# bucket = s3.Bucket(era5_bucket)\n",
    "\n",
    "# No AWS keys required\n",
    "client = boto3.client('s3', config=botocore.client.Config(signature_version=botocore.UNSIGNED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e95d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979/\n",
      "1980/\n",
      "1981/\n",
      "1982/\n",
      "1983/\n",
      "1984/\n",
      "1985/\n",
      "1986/\n",
      "1987/\n",
      "1988/\n",
      "1989/\n",
      "1990/\n",
      "1991/\n",
      "1992/\n",
      "1993/\n",
      "1994/\n",
      "1995/\n",
      "1996/\n",
      "1997/\n",
      "1998/\n",
      "1999/\n",
      "2000/\n",
      "2001/\n",
      "2002/\n",
      "2003/\n",
      "2004/\n",
      "2005/\n",
      "2006/\n",
      "2007/\n",
      "2008/\n",
      "2009/\n",
      "2010/\n",
      "2011/\n",
      "2012/\n",
      "2013/\n",
      "2014/\n",
      "2015/\n",
      "2016/\n",
      "2017/\n",
      "2018/\n",
      "2019/\n",
      "2020/\n",
      "2021/\n",
      "2022/\n",
      "QA/\n",
      "zarr/\n"
     ]
    }
   ],
   "source": [
    "paginator = client.get_paginator('list_objects')\n",
    "result = paginator.paginate(Bucket=era5_bucket, Delimiter='/')\n",
    "for prefix in result.search('CommonPrefixes'):\n",
    "    print(prefix.get('Prefix'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96bab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19 objects available for May, 2022\n",
      "--\n",
      "2022/05/data/air_pressure_at_mean_sea_level.nc\n",
      "2022/05/data/air_temperature_at_2_metres.nc\n",
      "2022/05/data/air_temperature_at_2_metres_1hour_Maximum.nc\n",
      "2022/05/data/air_temperature_at_2_metres_1hour_Minimum.nc\n",
      "2022/05/data/dew_point_temperature_at_2_metres.nc\n",
      "2022/05/data/eastward_wind_at_100_metres.nc\n",
      "2022/05/data/eastward_wind_at_10_metres.nc\n",
      "2022/05/data/integral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation.nc\n",
      "2022/05/data/lwe_thickness_of_surface_snow_amount.nc\n",
      "2022/05/data/northward_wind_at_100_metres.nc\n",
      "2022/05/data/northward_wind_at_10_metres.nc\n",
      "2022/05/data/precipitation_amount_1hour_Accumulation.nc\n",
      "2022/05/data/sea_surface_temperature.nc\n",
      "2022/05/data/sea_surface_wave_from_direction.nc\n",
      "2022/05/data/sea_surface_wave_mean_period.nc\n",
      "2022/05/data/significant_height_of_wind_and_swell_waves.nc\n",
      "2022/05/data/snow_density.nc\n",
      "2022/05/data/surface_air_pressure.nc\n",
      "2022/05/main.nc\n"
     ]
    }
   ],
   "source": [
    "keys = []\n",
    "date = datetime.date(2022,5,1) # update to desired date\n",
    "prefix = date.strftime('%Y/%m/')\n",
    "\n",
    "response = client.list_objects_v2(Bucket=era5_bucket, Prefix=prefix)\n",
    "response_meta = response.get('ResponseMetadata')\n",
    "\n",
    "if response_meta.get('HTTPStatusCode') == 200:\n",
    "    contents = response.get('Contents')\n",
    "    if contents == None:\n",
    "        print(\"No objects are available for %s\" % date.strftime('%B, %Y'))\n",
    "    else:\n",
    "        for obj in contents:\n",
    "            keys.append(obj.get('Key'))\n",
    "        print(\"There are %s objects available for %s\\n--\" % (len(keys), date.strftime('%B, %Y')))\n",
    "        for k in keys:\n",
    "            print(k)\n",
    "else:\n",
    "    print(\"There was an error with your request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcc9f03b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\precipitation_amount_1hour_Accumulation.nc.BaC0b4dF'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m metadata_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/precipitation_amount_1hour_Accumulation.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m metadata_key \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m metadata_file\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mera5_bucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m ds_meta \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/precipitation_amount_1hour_Accumulation.nc\u001b[39m\u001b[38;5;124m'\u001b[39m, decode_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m ds_meta\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\boto3\\s3\\inject.py:190\u001b[0m, in \u001b[0;36mdownload_file\u001b[1;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\boto3\\s3\\transfer.py:320\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[1;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[0;32m    316\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[0;32m    317\u001b[0m     bucket, key, filename, extra_args, subscribers\n\u001b[0;32m    318\u001b[0m )\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\s3transfer\\futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\s3transfer\\futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\s3transfer\\tasks.py:139\u001b[0m, in \u001b[0;36mTask.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# If the task is not done (really only if some other related\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# task to the TransferFuture had failed) then execute the task's\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# main() method.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_and_set_exception(e)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\s3transfer\\tasks.py:162\u001b[0m, in \u001b[0;36mTask._execute_main\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Log what is about to be executed.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs_to_display\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 162\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_main(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# value to the return value from main().\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_final:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\s3transfer\\download.py:642\u001b[0m, in \u001b[0;36mIOWriteTask._main\u001b[1;34m(self, fileobj, data, offset)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_main\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileobj, data, offset):\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;124;03m\"\"\"Pulls off an io queue to write contents to a file\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    :param fileobj: The file handle to write content to\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m    :param data: The data to write\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m    :param offset: The offset to write the data to.\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m     \u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    643\u001b[0m     fileobj\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\s3transfer\\utils.py:378\u001b[0m, in \u001b[0;36mDeferredOpenFile.seek\u001b[1;34m(self, where, whence)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mseek\u001b[39m(\u001b[38;5;28mself\u001b[39m, where, whence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj\u001b[38;5;241m.\u001b[39mseek(where, whence)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\s3transfer\\utils.py:361\u001b[0m, in \u001b[0;36mDeferredOpenFile._open_if_needed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_if_needed\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 361\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_byte \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    363\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_byte)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\s3transfer\\utils.py:272\u001b[0m, in \u001b[0;36mOSUtils.open\u001b[1;34m(self, filename, mode)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename, mode):\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\precipitation_amount_1hour_Accumulation.nc.BaC0b4dF'"
     ]
    }
   ],
   "source": [
    "metadata_file = 'main.nc'\n",
    "metadata_key = prefix + metadata_file\n",
    "client.download_file(era5_bucket, metadata_key, metadata_file)\n",
    "ds_meta = xr.open_dataset('main.nc', decode_times=False)\n",
    "ds_meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd1118e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dataset.info of <xarray.Dataset>\n",
       "Dimensions:                                  (lon: 1440, lat: 721, time1: 744,\n",
       "                                              nv: 2)\n",
       "Coordinates:\n",
       "  * lon                                      (lon) float32 0.0 0.25 ... 359.8\n",
       "  * lat                                      (lat) float32 90.0 89.75 ... -90.0\n",
       "  * time1                                    (time1) datetime64[ns] 2022-05-0...\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    time1_bounds                             (time1, nv) datetime64[ns] ...\n",
       "    precipitation_amount_1hour_Accumulation  (time1, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    source:       Reanalysis\n",
       "    institution:  ECMWF\n",
       "    title:        ERA5 forecasts>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select date and variable of interest\n",
    "date = datetime.date(2022,5,1)\n",
    "var = 'precipitation_amount_1hour_Accumulation'\n",
    "\n",
    "# file path patterns for remote S3 objects and corresponding local file\n",
    "s3_data_ptrn = '{year}/{month}/data/{var}.nc'\n",
    "data_file_ptrn = '{year}{month}_{var}.nc'\n",
    "\n",
    "year = date.strftime('%Y')\n",
    "month = date.strftime('%m')\n",
    "s3_data_key = s3_data_ptrn.format(year=year, month=month, var=var)\n",
    "data_file = data_file_ptrn.format(year=year, month=month, var=var)\n",
    "\n",
    "if not os.path.isfile(data_file): # check if file already exists\n",
    "    print(\"Downloading %s from S3...\" % s3_data_key)\n",
    "    client.download_file(era5_bucket, s3_data_key, data_file)\n",
    "\n",
    "ds = xr.open_dataset(data_file)\n",
    "ds.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb54333e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValuesView(Coordinates:\n",
       "  * lon      (lon) float32 0.0 0.25 0.5 0.75 1.0 ... 359.0 359.2 359.5 359.8\n",
       "  * lat      (lat) float32 90.0 89.75 89.5 89.25 ... -89.25 -89.5 -89.75 -90.0\n",
       "  * time1    (time1) datetime64[ns] 2022-05-01 ... 2022-05-31T23:00:00)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.coords.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7957dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6c0ef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.5 GiB for an array with shape (1440, 721, 744, 2) and data type datetime64[ns]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_f \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_f\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\xarray\\core\\dataset.py:6201\u001b[0m, in \u001b[0;36mDataset.to_dataframe\u001b[1;34m(self, dim_order)\u001b[0m\n\u001b[0;32m   6173\u001b[0m \u001b[38;5;124;03m\"\"\"Convert this dataset into a pandas.DataFrame.\u001b[39;00m\n\u001b[0;32m   6174\u001b[0m \n\u001b[0;32m   6175\u001b[0m \u001b[38;5;124;03mNon-index variables in this dataset form the columns of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6196\u001b[0m \n\u001b[0;32m   6197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6199\u001b[0m ordered_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_dim_order(dim_order\u001b[38;5;241m=\u001b[39mdim_order)\n\u001b[1;32m-> 6201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mordered_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordered_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\xarray\\core\\dataset.py:6165\u001b[0m, in \u001b[0;36mDataset._to_dataframe\u001b[1;34m(self, ordered_dims)\u001b[0m\n\u001b[0;32m   6163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m, ordered_dims: Mapping[Any, \u001b[38;5;28mint\u001b[39m]):\n\u001b[0;32m   6164\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims]\n\u001b[1;32m-> 6165\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6166\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables[k]\u001b[38;5;241m.\u001b[39mset_dims(ordered_dims)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   6167\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m columns\n\u001b[0;32m   6168\u001b[0m     ]\n\u001b[0;32m   6169\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39mto_index([\u001b[38;5;241m*\u001b[39mordered_dims])\n\u001b[0;32m   6170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(columns, data)), index\u001b[38;5;241m=\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jua\\lib\\site-packages\\xarray\\core\\dataset.py:6166\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   6163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m, ordered_dims: Mapping[Any, \u001b[38;5;28mint\u001b[39m]):\n\u001b[0;32m   6164\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims]\n\u001b[0;32m   6165\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 6166\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mordered_dims\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6167\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m columns\n\u001b[0;32m   6168\u001b[0m     ]\n\u001b[0;32m   6169\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39mto_index([\u001b[38;5;241m*\u001b[39mordered_dims])\n\u001b[0;32m   6170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(columns, data)), index\u001b[38;5;241m=\u001b[39mindex)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.5 GiB for an array with shape (1440, 721, 744, 2) and data type datetime64[ns]"
     ]
    }
   ],
   "source": [
    "df_f = ds.to_dataframe()\n",
    "df_f.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf6307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jua",
   "language": "python",
   "name": "jua"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
