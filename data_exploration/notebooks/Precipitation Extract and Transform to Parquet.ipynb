{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook environment.\n",
    "import boto3\n",
    "import botocore\n",
    "import datetime\n",
    "import os.path\n",
    "import xarray as xr\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b38942",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DATA_DIR = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c124bd5",
   "metadata": {},
   "source": [
    "## Data Exploration and Download\n",
    "A majority of the code from this section was taken from planet-os repo, referenced in the readme and linked here:\n",
    "https://github.com/planet-os/notebooks/blob/master/aws/era5-s3-via-boto.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd03dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_bucket = 'era5-pds'\n",
    "\n",
    "# AWS access / secret keys required\n",
    "# s3 = boto3.resource('s3')\n",
    "# bucket = s3.Bucket(era5_bucket)\n",
    "\n",
    "# No AWS keys required\n",
    "client = boto3.client('s3', config=botocore.client.Config(signature_version=botocore.UNSIGNED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e95d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = client.get_paginator('list_objects')\n",
    "result = paginator.paginate(Bucket=era5_bucket, Delimiter='/')\n",
    "for prefix in result.search('CommonPrefixes'):\n",
    "    print(prefix.get('Prefix'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96bab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "date = datetime.date(2022,5,1) # update to desired date\n",
    "prefix = date.strftime('%Y/%m/')\n",
    "\n",
    "response = client.list_objects_v2(Bucket=era5_bucket, Prefix=prefix)\n",
    "response_meta = response.get('ResponseMetadata')\n",
    "\n",
    "if response_meta.get('HTTPStatusCode') == 200:\n",
    "    contents = response.get('Contents')\n",
    "    if contents == None:\n",
    "        print(\"No objects are available for %s\" % date.strftime('%B, %Y'))\n",
    "    else:\n",
    "        for obj in contents:\n",
    "            keys.append(obj.get('Key'))\n",
    "        print(\"There are %s objects available for %s\\n--\" % (len(keys), date.strftime('%B, %Y')))\n",
    "        for k in keys:\n",
    "            print(k)\n",
    "else:\n",
    "    print(\"There was an error with your request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select date and variable of interest\n",
    "date = datetime.date(2022,5,1)\n",
    "var = 'precipitation_amount_1hour_Accumulation'\n",
    "\n",
    "# file path patterns for remote S3 objects and corresponding local file\n",
    "s3_data_ptrn = '{year}/{month}/data/{var}.nc'\n",
    "data_file_ptrn = '{year}{month}_{var}.nc'\n",
    "\n",
    "year = date.strftime('%Y')\n",
    "month = date.strftime('%m')\n",
    "s3_data_key = s3_data_ptrn.format(year=year, month=month, var=var)\n",
    "data_file = data_file_ptrn.format(year=year, month=month, var=var)\n",
    "\n",
    "if not os.path.isfile(data_file): # check if file already exists\n",
    "    print(\"Downloading %s from S3...\" % s3_data_key)\n",
    "    client.download_file(era5_bucket, s3_data_key, data_file)\n",
    "\n",
    "ds = xr.open_dataset(data_file)\n",
    "ds.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.time1.encoding[\"units\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca37543",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f5a33a",
   "metadata": {},
   "source": [
    "## Extract and save as parquet\n",
    "Extract a small subset of the data by date to test the workflow localy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02967f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_small=ds.sel(time1=slice('2022-05-01T22:00:00','2022-05-01T23:00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from xarray to pandas df\n",
    "df_f = ds_small.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf6307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the subset of localy to a compressed parquet\n",
    "df_f.to_parquet(f'{DATA_DIR}\\df.parquet.gzip', compression='gzip') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
